

# Install
https://ollama.com/download


# List of available Models
https://ollama.com/library

Small, fast models:
```
phi3:mini
gemma:2b
tinyllama
```

Better, ~ comparable with GPT3.5
```
llama3:8b
mistral
gemma:7b
```

High Performance
```
llama3:70b
mixtral
```


# Run in Terminal
List installed models
```
ollama list
```

(models will download on first run)
```
ollama run llama3:8b

/bye
```
# Run in GUI
See taskbar


# OLLAMA Server
```
ollama serve
```